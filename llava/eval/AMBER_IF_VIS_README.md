# AMBER Information Flow Visualization

This guide explains how to evaluate AMBER results and visualize information flow patterns.

## Files Created

1. **eval_amber.if_vis.py** - Main evaluation script with information flow visualization
2. **eval_amber_if_vis.sh** - Helper shell script to run evaluation

## Quick Start

### Step 1: Run Inference (Generate Results)

First, you need to run your model on AMBER to generate results with information flow data:

```bash
cd /home/jixu233b/Projects/VLM_3D/SpatialMllmHallucinate/third_party/cca-llava

# Create output directory
mkdir -p output/amber

# Run inference with CCA model (includes information flow)
python llava/eval/model_vqa_amber.cca.if_vis.py \
  --model-path your_model_path \
  --question-file playground/data/amber/query/query_all.json \
  --image-folder playground/data/amber/image \
  --answers-file output/amber/your_model_amber_ans.jsonl \
  --temperature 0 \
  --conv-mode vicuna_v1
```

**Note:** You need to use `model_vqa_amber.cca.if_vis.py` (with CCA) to get information flow data!

### Step 2: Visualize Information Flow

Once you have results, run the visualization:

```bash
python llava/eval/eval_amber.if_vis.py \
  --question-file playground/data/amber/query/query_all.json \
  --result-file output/amber/your_model_amber_ans.jsonl \
  --annotation-file playground/data/amber/annotations.json \
  --result-png output/amber/amber_information_flow.png \
  --split-by-type
```

Or use the helper script (after updating the model name):

```bash
# Edit the script first to set your result file path
nano llava/eval/eval_amber_if_vis.sh

# Then run
bash llava/eval/eval_amber_if_vis.sh
```

## Parameters

### Required Parameters:

- `--question-file`: Path to AMBER query JSON file
  - Example: `playground/data/amber/query/query_all.json`
  - Can also use `query_discriminative.json` or `query_generative.json`

- `--result-file`: Path to inference results JSONL file
  - Must contain `text_image_if` field (information flow data)
  - Generated by running inference with CCA model

- `--annotation-file`: Path to AMBER annotations JSON
  - Example: `playground/data/amber/annotations.json`

- `--result-png`: Output path for visualization PNG
  - Example: `output/amber/amber_information_flow.png`

### Optional Parameters:

- `--split-by-type`: Generate separate visualizations for:
  - Generative questions
  - Discriminative questions

## Output

The script generates:

1. **Hallucination Metrics**: Printed to console
   - Recall (correct object mentions)
   - Precision
   - F1 Score
   - Hallucination Rate

2. **Information Flow Visualization**: Saved as PNG
   - Overall attention heatmap
   - If `--split-by-type`: separate heatmaps for generative/discriminative

## Example Output

```
================================================================================
Total Samples: 1000
Total Ground Truth Objects: 5000
Correct Mentions: 4200
Hallucinated Mentions: 300
Recall: 0.8400
Precision: 0.9333
F1 Score: 0.8842
Hallucination Rate: 0.3000
================================================================================
Visualization saved to: output/amber/amber_information_flow.png
```

## Troubleshooting

### Error: "'text_image_if' not found in answer"

**Problem**: Your results don't contain information flow data.

**Solution**: Make sure you used the CCA model version when running inference:
- Use `model_vqa_amber.cca.if_vis.py` instead of `model_vqa_amber.py`
- The model must be trained/configured with CCA (Cross-modal Causal Attention)

### Error: "Result file not found"

**Problem**: You haven't run inference yet.

**Solution**: Run Step 1 above to generate results first.

## Files Structure

```
playground/data/amber/
├── image/                  # AMBER images
├── query/
│   ├── query_all.json     # All questions
│   ├── query_discriminative.json
│   └── query_generative.json
├── annotations.json        # Ground truth + hallucinations
├── relation.json          # Word associations
└── safe_words.txt         # Safe word list

output/amber/
├── your_model_amber_ans.jsonl           # Inference results
├── amber_information_flow.png           # Overall visualization
├── amber_information_flow_generative.png    # (if --split-by-type)
└── amber_information_flow_discriminative.png # (if --split-by-type)
```

## Next Steps

1. Run inference on your model to generate results
2. Use this script to evaluate and visualize
3. Compare information flow patterns across different models
4. Analyze where models focus attention during hallucination
